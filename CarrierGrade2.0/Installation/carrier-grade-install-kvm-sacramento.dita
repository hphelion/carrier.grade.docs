<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic1107cgiks">
<title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 2.0: Deploying the KVM Region in a
    Sacramento Deployment </title>
<prolog>
  <metadata>
    <othermeta name="layout" content="default"/>
    <othermeta name="product-version" content="HP Helion OpenStack Carrier Grade 2.0"/>
    <othermeta name="role" content="Storage Administrator"/>
    <othermeta name="role" content="Storage Architect"/>
    <othermeta name="role" content="Michael B"/>
    <othermeta name="product-version1" content="HP Helion OpenStack Carrier Grade 2.0"/>
  </metadata>
</prolog>
<body>
    <section id="intro">
      <p>After the lifecycle manager is up and running and HP Helion OpenStack is installed, use the
        following steps to deploy the KVM region.</p>
      <p>The process for installing the KVM region involves the following tasks:<ul
          id="ul_fj4_mct_g5">
          <li><xref href="#topic1107cgiks/controller-0" format="dita"/></li>
          <li><xref href="#topic1107cgiks/install-cloud" format="dita"/></li>
          <li><xref href="#topic1107cgiks/unlock" format="dita"/></li>
          <li><xref href="#topic1107cgiks/ssl" format="dita"/></li>
        </ul></p>
    </section>
    <section id="controller-0">
      <title>Step 1: Bring Up Controller-0 in the KVM Region</title>
      <ol id="ol_mf2_knq_35">
        <li>Make sure the server you will use for controller-0 is powered on and the other servers
          to be used in KVM region are shutdown.</li>
        <li>Launch the iLO interface for the server.</li>
        <li>Execute the following command to use the <codeph>bootimage_full.iso</codeph> to boot the
          controller node.<codeblock>mount bootimage_full.iso</codeblock></li>
        <li>Follow the install wizard. Select the Graphics mode for the controller only. Do not
          select <codeph>Controller+Compute</codeph>.<p>After the installation is complete, you will
            need to reboot the server. After the reboot:</p></li>
      </ol>
      <ol id="controller-0-2">
        <li>Log in as user name <codeph>wrsroot</codeph> and password <codeph>wrsroot</codeph>. Make
          sure you change the password.</li>
        <li>Temporarily assign an IP address to the <codeph>PXE NIC - eth0</codeph>. Use the IP you
          have reserved for the KVM PXE.
          <codeblock>ip addr add &lt;CIDR> dev eth0
ifconfig eth0 up</codeblock></li>
        <li> Set the default gateway to the PXE network gateway
          <codeblock>route add default gw &lt;CIDR_gateway_IP&gt;</codeblock></li>
        <li>Copy the following KVM revion license files from the lifecycle manager to the
            <codeph>/home/wrsroot/</codeph> directory of the <codeph>controller-0</codeph>. <ul
            id="ul_mpn_hnr_bt">
            <li><codeph>license.lic</codeph> Located in the
                <codeph>/root/cg-hlm/windriver-files</codeph> directory</li>
            <li><codeph>region_config</codeph> Located in the
                /<codeph>var/hlm/clouds/&lt;cloud-name&gt;/desired_state/&lt;cloud-name&gt;/001/base/stage/windriver-config</codeph>
              directory</li>
            <li><codeph>cakey.pem</codeph> Located in the
                <codeph>/var/hlm/clouds/&lt;cloud-name&gt;/desired_state/&lt;cloud-name&gt;/001/base/stage/windriver-config</codeph>
              directory</li>
          </ul><p>These files are loaded to the lifecycle manager during the installation
            process.</p></li>
      </ol>
    </section>
    <section id="install-cloud">
      <title>Step 2: Configure the KVM region cloud</title>
      <ol>
        <li>In the iLO web interface, launch a console session to the <codeph>controller-0</codeph>
          node.</li>
        <li>Execute the following command to install the KVM region cloud:<p><b>Important:</b>
            Always execute this command from a console window, not an SSH
              session</p><codeblock>sudo config_region region_config</codeblock><p><image
              href="../../media/CGH-install-KVM.png" width="500" id="image_c2w_4kk_bt"/></p>Ignore
          the message which displays during <codeph>config_region</codeph> process.
              <codeblock>Step 9 of 29 [####  ]dm-6 WRITE SAME failed. Manually zeroing. </codeblock><p><image
              href="../../media/CGH-install-kvm-error.png" width="500"/></p></li>
        <li>After <codeph>controller-0</codeph> is deployed, add and configure the remaining nodes
          as <codeph>controller-1</codeph> and <codeph>compute-'n'</codeph>.
              <codeblock>system host-add --hostname controller-1 --personality controller --mgmt_mac &lt;mgmt_mac&gt; --bm_mac &lt;bm_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt; --bm_password &lt;ilo_password&gt;
system host-add --hostname &lt;unique-compute-name&gt; --personality compute --mgmt_mac &lt;mgmt_mac&gt; --bm_mac &lt;ilo_mac&gt; --bm_ip &lt;ilo_ip&gt; --bm_type ilo4 --bm_username &lt;ilo_user&gt;  --bm_password &lt;ilo_password&gt;</codeblock><p><b>Note:</b>
            When adding a controller, the name is assigned in order. Unique controller names are
            ignored.</p><p><image href="../../media/CGH-install-kvm-host-add.png"
              id="image_tv5_wz1_ct" width="300"/></p></li>
        <li>In the iLO web interface, set the controller and compute nodes to one-time PXE booting
          from the network.</li>
        <li>Restart the nodes.</li>
        <li><xref href="carrier-grade-install-launch-horizon.dita#topic10581cgilh">Access the
            Horizon dashboard</xref> using the CAN network IP (HTTPS). </li>
        <li>Select <b>regionkvm</b> in the <xref
            href="../OperationsGuide/Dashboard/CGH-2-User-region-selector.dita#jow1432757989702"
            >region selector</xref>.</li>
        <li>Click <b>Admin</b> then <b>Inventory</b> to monitor the status of nodes being PXE
          booted. After a succesful PXE boot, the <b>Operational State</b> should be <b>Disabled</b>
          and the <b>Availability State</b> should be <b>Online</b>. <p><b>Note:</b>The Horizon
            Dashboard will be running on the first IP address of the CLM network range (refer to the
              <codeph>ip_start_address</codeph> value provided for the CLM network in the
              <codeph>definition.json</codeph> during the non-KVM Region deployment). </p><p>The
            log-in credentials for Horizon are as
            follows:</p><codeblock>username: admin 
password:  &lt;random></codeblock><p>The Horizon
            password is randomly generated during the installation. You can locate the password in
            the <codeph>stackrc</codeph> file on any of the non-KVM region controllers.</p></li>
      </ol>
    </section>
    <section id="unlock">
      <title>Step 3: Configure and unlock the compute controllers</title>
      <p>After the controller-1 and the compute nodes come up successfully after PXE boot, execute
        the following commands from controller-0 to unlock each compute node in the inventory.</p>
      <ul id="ul_f1c_dk1_h5">
        <li><xref href="#topic1107cgiks/kvm-esx-unlock" format="dita">For a Non-Bonded Environment</xref></li>
        <li><xref href="#topic1107cgiks/nic-unlock" format="dita">For a Bonded Environment</xref></li>
      </ul>
    
    <p id="kvm-esx-unlock">
      <b>For a Non-Bonded Environment</b></p>
      <ol>
        <li>After the controller-1 and the compute nodes come up successfully after PXE boot,
          execute the following commands from controller-0 to unlock the compute nodes.<ol
            id="ol_p42_d35_lt">
            <li>Create the Infra interface:
              <codeblock>system host-if-add –V &lt;bls/infra VLAN ID&gt; –nt &lt;network_type> &lt;host-name or ID> &lt;interface_name> &lt;interface_type> &lt;port or interfaces></codeblock></li>
            <li>Add an IP address to the Infra interface:
              <codeblock>system host-addr-add &lt;host-name or ID> &lt;interface_name> &lt;ipv4/ipv6_address> &lt;prefix-length></codeblock></li>
            <li>Configure the VRS interface:
                <codeblock>system host-if-modify &lt;host-name or ID> -n &lt;interface_name> -nt &lt;network_type> --ipv4-mode=static eth-x </codeblock><p>Where
                  <codeph>eth-x</codeph> is the interface on which untagged TUL is
              presented.</p></li>
            <li>Add an IP address to the VRS interface:
              <codeblock>system host-addr-add &lt;host-name or ID> vrs &lt;ipv4/ipv6_address> &lt;prefix_length></codeblock></li>
            <li>Update the host:
                <codeblock> system host-update &lt;host-name or ID> vsc_controllers=&lt;ipv4/ipv6_address>,&lt;ipv4/ipv6_address> </codeblock><p>Enter
                the IP address of the VSC controllers</p></li>
            <li>Unlock the host: <codeblock>system host-unlock &lt;host-name or ID></codeblock></li>
          </ol><p><b>Example
          commands:</b></p><codeblock>system host-if-add –V 722 –nt infra compute-3 infra vlan pxeboot0
system host-addr-add compute-3 infra 10.70.22.81 24
system host-if-modify compute-3 -n vrs -nt data-vrs --ipv4-mode=static eth4
system host-addr-add compute-3 vrs 10.70.5.83 24
system host-update compute-3 vsc_controllers=10.70.5.31,10.70.5.32
system host-unlock compute-3        </codeblock></li>
      </ol>
    
    <p id="nic-unlock">
      <b>For bonded NIC environments</b></p>
      <p>If you are using a bonded NIC environment, after configuring and unlocking the compute
        nodes, perform these steps:</p>
      <ol id="ol_nr5_ddw_mt">
        <li>Use the following commands to delete the MGMT interface: <ol id="ol_zfq_5h1_tt">
            <li>Obtain the compute name or ID number:<codeblock>system host-list</codeblock></li>
            <li>Obtain the UUID of the MGMT interface to
              remove:<codeblock>system host-if-list</codeblock></li>
            <li>Remove the PXE boot flag off the
              interface:<codeblock>system host-if-modify -nt "none" compute-0 pxeboot0</codeblock></li>
            <li>Delete the
              interface:<codeblock>system host-if-delete compute-0 95e7b495-1454-49d1-8123-301215503e86      </codeblock></li>
          </ol></li>
        <li>Use the following commands to create a bonded interface and setup node to be unlocked:
          <codeblock>system host-if-add -a 802.3ad -x layer2 -nt pxeboot compute-0 bond0 ae "none" eth0 eth1
system host-if-add -V 303 -nt mgmt compute-0 mgmt vlan bond0
system host-if-add -V 74 -nt infra compute-0 infra vlan bond0
system host-addr-add compute-0 infra 172.16.74.244 24
system host-if-add -a balanced -x layer2 -nt "none" compute-0 bondvrs ae "none" eth2 eth3</codeblock></li>
        <li>Use one of the following steps to configure a static IP address for the bonded NIC
          interface or assign an IP address from an IP address pool:<ul id="ol_uqd_l5z_st">
            <li>To assign a static IP:
              <codeblock>system host-if-modify compute-0 -nt data-vrs --ipv4-mode=static bondvrs
system host-addr-add compute-0 bondvrs 10.30.6.244 24</codeblock></li>
            <li>To assign an IP address from a pool:<p>
                <codeblock>system addrpool-add vrspool 10.30.6.0 24 --order random --ranges 10.30.6.240-10.30.6.249
system host-if-modify compute-0 bondvrs -nt data-vrs --ipv4-mode=pool --ipv4-pool=vrspool
system host-if-modify compute-1 bondvrs -nt data-vrs --ipv4-mode=pool --ipv4-pool=vrspool</codeblock>
              </p></li>
          </ul></li>
        <li>Execute the following command to assign IP addresses to
          compute-0:<codeblock>system host-update compute-0 vsc_controllers=10.30.6.31,10.30.6.32</codeblock></li>
      </ol>
    </section>
    <section id="ssl">
      <title>Step 5: Install Required SSL Certificate</title>
      <p>If you want to Opentsack CLIs in the KVM region from a remote client, use the following
        steps to install a required SSL certificate.</p>
      <p>
        <ol id="ol_k5p_bys_g5">
          <li>Log into the KVM region <codeph>controller-0</codeph>, the active controller as
            root:<codeblock>sudo -i</codeblock></li>
          <li>Copy the <xref href="#topic1107cgiks/script" format="dita">patch script below</xref>
            into a text editor and save as <codeph>wrvippem.sh</codeph> in the
              <codeph>/home/wrsroot/</codeph> directory.</li>
          <li>Edit the script to set <codeph>WR_VIP</codeph> field to the KVM region endpoint.</li>
          <li>Execute the following command to deploy the script using bash
            <codeblock>+x wrvippem.sh</codeblock></li>
          <li>Change to the following directory: <codeblock>cd /etc/ssl/private</codeblock></li>
          <li>Copy the <codeph>server-cert.pem</codeph> in that directory to the
              <codeph>/etc/ssl/private</codeph> directory on the KVM region
              <codeph>controller-1</codeph>, the standby controller.</li>
        </ol>
      </p>
    
    <p id="script">
      <b>SSL Certificate Script</b></p>
      <p>Use the following to copy and paste into a script file in your environment. Save the file
        as <codeph>wrvippem.sh</codeph> and copy to the KVM region
        <codeph>controller-0</codeph>.<codeblock>#### CUSTOMER SUPPLIED VARIABLES ####
#
# This script will resolve the following error returned by nova list.
#
# root@BASE-CCP-T2-M1-NETCLM:~# nova list
# ERROR (SSLError): SSL exception connecting to https://10.20.4.50:8774/v2/f8a434/servers/detail: hostname '10.20.4.50' doesn't match u'Autogenerated HLM Certificate Authority'
#
# WR_VIP:
# In the above scenario, set WR_VIP to 10.20.4.50.
#
# SSL_PASSPHRASE:
# Set SSL_PASSPHRASE to the value of ssl_passphrase in
# /var/hlm/clouds/&lt;cloud_name>/vars/ansible.json. By default this is 'cghelion'.
#

WR_VIP=xxx.xxx.xxx.xxx
SSL_PASSPHRASE=cghelion
#####################################

# create temporary directory
ssl_rootdir=`mktemp -d`

# set variables
cakey=/etc/ssl/private/key.pem
cacert=/etc/ssl/private/cert.pem
config=$ssl_rootdir/certs/openssl_req.conf
req=$ssl_rootdir/certs/$WR_VIP.req
cert=$ssl_rootdir/certs/$WR_VIP.crt
vipkey=$ssl_rootdir/private/$WR_VIP.pem
passin=
if [ ! -z $SSL_PASSPHRASE ]; then
    passin="-passin pass:$SSL_PASSPHRASE"
fi

# change to temporary directory
pushd $ssl_rootdir >/dev/null

# write some directories and files
mkdir $ssl_rootdir/certs
mkdir $ssl_rootdir/private
touch $ssl_rootdir/certs/index.txt
cat &lt;&lt;EOF >> $ssl_rootdir/certs/serial
01
EOF
cat &lt;&lt;EOF >> $config

# OpenSSL configuration file.
#

# Establish working directory.

dir            = $ssl_rootdir/certs

[ ca ]
default_ca        = CA_default

[ CA_default ]
new_certs_dir     = \$dir
serial            = \$dir/serial
database          = \$dir/index.txt
default_days      = 365
default_md        = default
preserve          = no
email_in_dn       = no
nameopt           = default_ca
certopt           = default_ca
policy            = policy_anything
x509_extensions   = usr_cert
unique_subject    = no
copy_extensions   = copy

[ policy_anything ]
countryName             = optional
stateOrProvinceName     = optional
organizationName        = optional
organizationalUnitName  = optional
commonName              = supplied
emailAddress            = optional

[ req ]
default_bits       = 2048 # Size of keys
default_keyfile    = key.pem # name of generated keys
string_mask        = utf8only # permitted characters
distinguished_name = req_distinguished_name
req_extensions     = v3_req

[ req_distinguished_name ]
countryName                 = Country Name (2 letter code)
countryName_min             = 2
countryName_max             = 2
stateOrProvinceName         = State or Province Name (full name)
localityName                = Locality Name (city, district)
0.organizationName          = Organization Name (company)
organizationalUnitName      = Organizational Unit Name (department, division)
commonName                  = Common Name (hostname, IP, or your name)
commonName_max              = 64
emailAddress                = Email Address
emailAddress_max            = 64

[ v3_req ]
basicConstraints     = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
subjectAltName       = \${ENV::SAN}

[ usr_cert ]
basicConstraints       = CA:FALSE
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always

[ server_cert ]
basicConstraints = CA:FALSE
nsCertType = server
subjectKeyIdentifier = hash
authorityKeyIdentifier = keyid,issuer:always
keyUsage = critical, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
EOF

# run the openssl commands
export SAN="DNS:$WR_VIP"
openssl genrsa -out $vipkey >/dev/null
openssl req -extensions v3_req -key $vipkey -new -out $req -config $config -subj "/CN=$WR_VIP"
openssl ca -batch -out $cert -config $config -days 3650d -cert $cacert -keyfile $cakey $passin -infiles $req

# backup the old PEM file
if [ ! -f /etc/ssl/private/server-cert.pem.bak ]; then
    cp /etc/ssl/private/server-cert.pem /etc/ssl/private/server-cert.pem.bak
fi
# write the new PEM file
cat $cert > /etc/ssl/private/server-cert.pem
cat $vipkey >> /etc/ssl/private/server-cert.pem

# exit the temporary directory
popd >/dev/null

# remove the temporary directory
rm -rf $ssl_rootdir

# apply the new PEM file
service haproxy restart
</codeblock></p>
    </section>
    <section><title>Deploy the Horizon Patch</title>You should have downloaded the following patch
      files during the prerequisites:<ul id="ul_awq_db1_f5">
        <li>WR-HZN-1011</li>
      </ul><p>The README with the patch download contains information on files changed by these
        patches.</p><p>Execute the following commands:<ol id="ol_imr_fgt_25">
          <li>Copy the WR-HZN-1011 directory to the
              <codeph>/var/hlm/clouds/&lt;cloudname>/patches</codeph> directory on the lifecycle
            manager. </li>
          <li>Execute following command to apply patch
              <codeblock>hlm patch -c &lt;cloud-name> -n WR-HZN-1011 -t &lt;tier></codeblock><p>Where:
              &lt;tier> is the tier on which the various controllers are running. </p>For example:
            <codeblock>hlm patch -c sac36 -n WR-HZN-1011 -t BASE-CCP-T2</codeblock>The tier
            information can be found in the
              <codeph>/var/hlm/clouds/&lt;cloudname>/desired_state/sac36/001/base/stage/ansible/hosts</codeph>
            file. </li>
        </ol></p></section>
    <section id="next-step">
      <title>Next Steps</title>
      <p><xref href="carrier-grade-install-post.dita#topic1107cgipd">Post-Installation
        Tasks</xref></p>
    </section>
  </body>
</topic>
