<?xml version="1.0" encoding="UTF-8"?><?workdir /C:\Drop3and4\Drop4\temp\pdf\oxygen_dita_temp?><?workdir-uri file:/C:/Drop3and4/Drop4/temp/pdf/oxygen_dita_temp/?><?path2project?><?path2project-uri ./?><concept-wr xmlns:ditaarch="http://dita.oasis-open.org/architecture/2005/" domains="(topic concept concept-wr)                            (topic hi-d)                            (topic indexing-d)                            (topic pr-d)                            (topic sw-d)                            (topic ui-d)                            (topic wr-sw-d)                            (topic xml-d)   " id="jow1404333768530" xml:lang="en-us" ditaarch:DITAArchVersion="1.2" class="- topic/topic concept/concept concept-wr/concept-wr ">
    <!-- Modification History
   -->
    <title ixia_locid="1" class="- topic/title ">Processor</title>
    <shortdesc ixia_locid="2" class="- topic/shortdesc ">The <uicontrol ixia_locid="3" class="+ topic/ph ui-d/uicontrol ">Processor</uicontrol> tab on the
            <wintitle ixia_locid="4" class="+ topic/keyword ui-d/wintitle ">Inventory Detail</wintitle> page presents processor details for
        a host, as illustrated below.</shortdesc>
    <prolog class="- topic/prolog ">
        <author ixia_locid="56" class="- topic/author ">Jim Owens</author>
        <author ixia_locid="5" class="- topic/author ">Pedro Sanchez</author>
    </prolog>
    <conbody class="- topic/body  concept/conbody ">
        <fig id="fig_N10027_N10024_N10001" ixia_locid="6" class="- topic/fig ">
            <image href="jow1404333763192.image" id="image_iqn_jlz_l4" ixia_locid="7" width="6in" placement="inline" class="- topic/image "/>
        </fig>
        <p ixia_locid="8" class="- topic/p ">The <uicontrol ixia_locid="9" class="+ topic/ph ui-d/uicontrol ">Processor</uicontrol> tab includes the following items:</p>
        <ul id="ul_stv_nlz_l4" class="- topic/ul ">
            <li ixia_locid="10" class="- topic/li ">
                <p ixia_locid="11" class="- topic/p ">processor model, number of processors, number of cores per
                    processor, and Hyper-Threading status (enabled or disabled).</p>
            </li>
            <li ixia_locid="12" class="- topic/li ">
                <p ixia_locid="13" class="- topic/p ">the CPU assignments. See section <xref href="jow1404333787693.xml#jow1404333787693/cpu-profiles" ixia_locid="14" class="- topic/xref "/> for more details.</p>
            </li>
        </ul>
        <p ixia_locid="15" class="- topic/p ">Two buttons are also available as follows:</p>
        <dl class="- topic/dl ">
            <dlentry ixia_locid="16" class="- topic/dlentry ">
                <dt ixia_locid="17" class="- topic/dt "><uicontrol ixia_locid="18" class="+ topic/ph ui-d/uicontrol ">Create CPU Profile</uicontrol></dt>
                <dd ixia_locid="19" class="- topic/dd ">
                    <p ixia_locid="20" class="- topic/p ">Clicking this button displays the <wintitle ixia_locid="21" class="+ topic/keyword ui-d/wintitle ">Create CPU Profile</wintitle> window, where
            the current CPU assignment can be given a name, as illustrated below.</p>
                    <fig id="fig_N1006F_N10064_N1005B_N10058_N10024_N10001" ixia_locid="22" class="- topic/fig ">
                        <image href="jow1404333764867.image" id="image_mj3_zmz_l4" ixia_locid="23" width="4in" placement="inline" class="- topic/image "/>
                    </fig>
                    <p ixia_locid="24" class="- topic/p ">In this example, you are about to create a CPU Profile named
              <nameliteral ixia_locid="25" class="+ topic/ph hi-d/b wr-sw-d/nameliteral ">HP-360-C1</nameliteral> out of the current CPU assignments found in a
            compute node.</p>
                </dd>
            </dlentry>
            <dlentry ixia_locid="26" class="- topic/dlentry ">
                <dt ixia_locid="27" class="- topic/dt "><uicontrol ixia_locid="28" class="+ topic/ph ui-d/uicontrol ">Edit CPU Assignments</uicontrol></dt>
                <dd ixia_locid="29" class="- topic/dd ">
                    <p ixia_locid="30" class="- topic/p ">This button is available only when the host is in the locked
                        state.</p>
                    <p ixia_locid="75" class="- topic/p ">Clicking this button displays the <wintitle ixia_locid="78" class="+ topic/keyword ui-d/wintitle ">Edit CPU Assignments</wintitle> window. On a compute node, you can use
                        this window to assign cores to specific functions, as illustrated below.
                        Unassigned cores are available for allocation to virtual machine threads. </p>
                    <fig id="fig_N1009D_N1008E_N10085_N10058_N10024_N10001" ixia_locid="33" class="- topic/fig ">
                        <image href="jow1404333766847.image" id="image_khm_xsz_l4" ixia_locid="34" placement="inline" class="- topic/image "/>
                    </fig>
                    <note id="note_N100CC_N100AF_N100A3_N1006C_N1002E_N10001" ixia_locid="79" class="- topic/note ">
                        <p ixia_locid="76" class="- topic/p ">On a controller or storage node, only the <nameliteral ixia_locid="80" class="+ topic/ph hi-d/b wr-sw-d/nameliteral ">Platform</nameliteral> function is shown, and all
                            available cores are automatically assigned as platform cores.</p>
                    </note>
                    <dl class="- topic/dl ">
                        <dlentry ixia_locid="63" class="- topic/dlentry ">
                            <dt ixia_locid="64" class="- topic/dt ">Platform</dt>
                            <dd ixia_locid="65" class="- topic/dd ">
                                <p ixia_locid="66" class="- topic/p ">You can reserve one or more cores in each NUMA
                                    node for platform use. <ph ixia_locid="81" product="tis_not_small" class="- topic/ph ">One core on each host is required to run
                                        the operating system and associated services.</ph><ph ixia_locid="82" product="tis_small" class="- topic/ph ">For a system with separate controller
                                        and compute nodes, one core on each host is required to run
                                        the operating system and associated services. For a combined
                                        controller and compute node in a minimal two-server
                                        configuration, two cores are required.</ph></p>
                                <p ixia_locid="73" class="- topic/p ">The ability to assign platform cores to specific NUMA nodes
                                    offers increased flexibility for high-performance
                                    configurations. For example, you can dedicate certain NUMA nodes
                                    for vSwitch or VM use, or affine VMs that require
                                    high-performance IRQ servicing with NUMA nodes that service the
                                    requests.</p>
                            </dd>
                        </dlentry>
                        <dlentry ixia_locid="67" class="- topic/dlentry ">
                            <dt ixia_locid="68" class="- topic/dt ">Vswitch</dt>
                            <dd ixia_locid="69" class="- topic/dd ">
                                <p ixia_locid="36" class="- topic/p ">AVS (vSwitch) cores can be configured for each
                                    processor independently. This means that the single logical
                                    vSwitch running on a compute node can make use of cores in
                                    multiple processors, or NUMA nodes. Optimal data path
                                    performance is achieved when all AVS cores, the physical ports,
                                    and the virtual machines that use them are running on the same
                                    processor. You can affine VMs to NUMA nodes with AVS cores; for
                                    more information, see <xref href="jow1436210207074.xml" ixia_locid="57" class="- topic/xref "/>. Alternatively, having AVS cores on all
                                    processors ensures that all virtual machines, regardless of the
                                    core they run on, are efficiently serviced. The example
                                    allocates two cores from processor 1 to the AVS threads.</p>
                            </dd>
                        </dlentry>
                        <dlentry ixia_locid="70" class="- topic/dlentry ">
                            <dt ixia_locid="71" class="- topic/dt ">Shared</dt>
                            <dd ixia_locid="72" class="- topic/dd ">
                                <p ixia_locid="54" class="- topic/p ">One physical core per processor can be configured
                                    as a shared CPU, which can be used by multiple VMs for low-load
                                    tasks. To use the shared physical CPU, each VM must be
                                    configured with a shared vCPU ID. For more information, see
                                        <xref href="jow1426625051841.xml" ixia_locid="55" class="- topic/xref "/>.</p>
                            </dd>
                        </dlentry>
                    </dl>
                </dd>
            </dlentry>
        </dl>
        <p ixia_locid="61" class="- topic/p ">To see how many cores a processor contains, hover over the Information
            icon.</p>
        <fig id="fig_kfq_vzq_ps" ixia_locid="58" class="- topic/fig ">
            <image href="jow1436300231676.image" id="image_cls_d1r_ps" ixia_locid="59" placement="inline" class="- topic/image ">
                <alt ixia_locid="60" class="- topic/alt ">TiS available cores tooltip</alt>
            </image>
        </fig>
<!--        <section id="section_N100DD_N10029_N10001" ixia_locid="38">
            <title ixia_locid="39">CPU Topology From the CLI</title>
            <p ixia_locid="40">You can use the <cmdname ixia_locid="41">vm-topology</cmdname>
                command from the CLI on the controller nodes to explore the enumeration of sockets,
                cores, and logical processors on a compute node. The command can be executed without
                root privileges or Keystone authentication. Here is an example:</p>
            <codeblock ixia_locid="42"><systemoutput ixia_locid="43">$ </systemoutput><userinput ixia_locid="44">vm-topology -s topology</userinput><systemoutput ixia_locid="45">
compute-1:  Model:SandyBridge, Arch:x86_64, Vendor:Intel, Sockets=2, Cores/Socket=12, Threads/Core=1
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+
|     cpu_id | 0 | 1 | 2 |... | 11 | 12 | 13 | 14 |... | 23 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+
|  socket_id | 0 | 0 | 0 |... |  0 |  1 |  1 |  1 |... |  1 |
|    core_id | 0 | 1 | 2 |... | 13 |  0 |  1 |  2 |... | 13 |
|  thread_id | 0 | 0 | 0 |... |  0 |  0 |  0 |  0 |... |  0 |
| sibling_id | - | - | - |... |  - |  - |  - |  - |... |  - |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-+-\-\-+-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+

compute-2:  Model:SandyBridge, Arch:x86_64, Vendor:Intel, Sockets=2, Cores/Socket=12, Threads/Core=2
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+
|     cpu_id |  0 |  1 |  2 |... | 11 | 12 | 13 | 14 |... | 46 | 47 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+
|  socket_id |  0 |  0 |  0 |... |  0 |  1 |  1 |  1 |... |  1 |  1 |
|    core_id |  0 |  1 |  2 |... | 13 |  0 |  1 |  2 |... | 12 | 13 |
|  thread_id |  0 |  0 |  0 |... |  0 |  0 |  0 |  0 |... |  1 |  1 |
| sibling_id | 24 | 25 | 26 |... | 35 | 36 | 37 | 38 |... | 22 | 23 |
+-\-\-\-\-\-\-\-\-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+-\-\-\-+-\-\-\-+... +-\-\-\-+-\-\-\-+</systemoutput></codeblock>
            <p ixia_locid="46">The example shows two compute nodes, <nameliteral ixia_locid="47">compute-1</nameliteral> with two sockets, 12 cores per socket, and no
                Hyper-Threading (Threads/Core=1), and <nameliteral ixia_locid="48">compute-2</nameliteral> with two sockets, 12 cores per socket, and
                Hyper-Threading enabled with two logical processors per core (Threads/Core=2). The
                rows <nameliteral ixia_locid="49">cpu_id</nameliteral> and <nameliteral ixia_locid="50">sibling_id</nameliteral> on <nameliteral ixia_locid="51">compute-2</nameliteral> node show the hyperthread sibling processors; cores in
                this compute node can therefore be described by the sequence [0, 24] [1, 25] [2, 26]
                ... [46, 22] [47, 23].</p>
            <p ixia_locid="52">Use the command <cmdname ixia_locid="53">vm-topology -\-help</cmdname> to list other available options
                to include information about virtual machine flavors, instances (servers), server
                groups, and  migrations in progress.</p>
        </section>
-->    </conbody>
</concept-wr>