<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic3485cgto">
<title>HPE Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 1.1: Technical Overview</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
  <othermeta name="product-version" content="HPE Helion Openstack Carreir Grade 1.1"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Storage Architect"/>
<othermeta name="role" content="Michael B"/>
  <othermeta name="product-version1" content="HPE Helion Openstack Carreir Grade 1.1"/>
</metadata>
</prolog>
<body>
    <p><!--UNDER REVISION--><!--./CarrierGrade/Installation/carrier-grade-technical-overview.md--><!--permalink: /helion/openstack/carrier/technical-overview/--></p>
    <p>This page introduces you to the technical aspects of the HPE Helion OpenStack Carrier Grade
      environment that you will be installing.</p>
    <ul>
      <li>
        <xref type="section" href="#topic3485cgto/Helion-services">HPE Helion OpenStack services</xref>
      </li>
      <li>
        <xref type="section" href="#topic3485cgto/deploy-arch">Deployment architecture</xref>
      </li>
      <li><xref href="#topic3485cgto/board-management-modules" format="dita"/>
      </li>
      <li><xref href="#topic3485cgto/usb-interface" format="dita"/></li>
      <li><xref href="#topic3485cgto/net" format="dita"/></li>
    </ul>
    <p>For more information on the HPE Helion OpenStack Carrier Grade environment, also see the
      Reference Logical Architecture section in the <xref
        href="http://docs.hpcloud.com/pdf/static/HP-Helion-OpenStack-Carrier-Grade-Admin-Guide.pdf"
        format="pdf" scope="external">HPE Helion OpenStack Carrier Grade 1.1: Administrator
        Guide</xref>.</p>
    <section id="Helion-services">
      <title>Services overview</title>
      <p>HPE Helion OpenStack Carrier Grade is comprised of several integrated OpenStack services.
        Each service works through an API (application programming interface) that allows services
        to work together and allows users to interact with the services. For a complete description
        of these services, see the <xref
          href="../../CarrierGrade/Overview/carrier-grade.services-overview.dita">Services
          Overview</xref> page.</p>
    </section>
    <section id="deploy-arch">
      <title>Deployment and network architectures</title>
      <p>See one of the following pages for the appropriate deployment and network architectures:<ul
          id="ul_th3_bpb_ws">
          <li><xref href="carrier-grade-technical-overview-kvm-only.dita#topic3485cgtoko">KVM Deployment
              Architecture Reference </xref></li>
          <li><xref href="carrier-grade-technical-overview-esx.dita#topic3485cgtoe">KVM + ESX Deployment
              Architecture Reference </xref></li>
        </ul></p>
      <title>Ethernet Interfaces</title>
      <p>All hosts in the server connect to at least the internal management network using an
        Ethernet interface. The ports used for this connection must support network booting and must
        be configured to be used as the primary booting device for normal operations.</p>
      <p>Typically this means that they must be on-board ports, since in most BIOS/UEFI
        implementations only on-board ports can be configured for network booting. You can use ports
        on a 10 GB NIC instead, if these ports fulfill these requirements.</p>
      <p>The following table illustrates the number and type of Ethernet ports required in two
        different installation scenarios. </p>
      <p>
        <b>NOTE:</b> The following table assumes that each interface is connected to a single
        network. An Ethernet interface can be shared by more than one network.</p>
      <table id="table_wpt_x4b_ws">
        <tgroup cols="3">
          <thead>
            <row>
              <entry>Personality</entry>
              <entry>Basic Scenario</entry>
              <entry>LAG Scenario</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Controller Node</entry>
              <entry>
                <ul id="ul_xpt_x4b_ws">
                  <li> One 10G on-board interface (Internal management network)</li>
                </ul>
              </entry>
              <entry>
                <ul id="ul_ypt_x4b_ws">
                  <li>Two 10G on-board interfaces (Internal management network)</li>
                </ul>
              </entry>
            </row>
            <row>
              <entry>Compute Node</entry>
              <entry>
                <ul id="ul_zpt_x4b_ws">
                  <li>One 10G on-board interface (Internal management network)</li>
                  <li>Two 10G (Intel 82599) interfaces per Provider Network</li>
                </ul>
              </entry>
              <entry>
                <ul id="ul_aqt_x4b_ws">
                  <li>Two 10G on-board interfaces (Internal management network)</li>
                  <li>Two 10G (Intel 82599) interfaces per Provider Network</li>
                </ul>
              </entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>In the basic scenario, a single Ethernet port is used to attach the host to each of the
        networks. In the LAG scenario, two Ethernet ports are used for each connection.</p>
    </section>
    <section id="board-management-modules">
      <title>Board Management Modules</title>
      <p>For out-of-band reset and power-on/power-off capabilities, DL360 or DL380 servers equipped
        with HPE iLO (Integrated Lights Out) board management modules are required. Each module must
        be connected using port-based VLAN to a switch that has access to the internal management
        network.</p>
    </section>
    <section id="usb-interface">
      <title>USB Interface</title>
      <p>For the controller, a USB interface is required for backup and restore operations, and for
        software installation if a DVD is not available.</p>
    </section>
    <section id="net">
      <title>Network Requirements</title>
      <p>The KVM regions networking environment incorporates up to five types of network:</p>
      <ul>
        <li><xref href="#topic3485cgdo/internal-management-network" format="dita">the internal
            management network</xref></li>
        <li><xref href="#topic3485cgto/oam-network" format="dita">the OAM network</xref></li>
        <li><xref href="#topic3485cgto/provider-network" format="dita">one or more provider
            networks</xref></li>
        <li><xref href="#topic3485cgto/infrastructure-network" format="dita">an optional infrastructure
            network</xref></li>
        <li><xref href="#topic3485cgto/board-network" format="dita">an optional board management network.</xref> </li>
      </ul>
      <p>Operational requirements for each network are described in the following sections.</p>
    </section>
    <section id="internal-management-network"><b>Internal Management Network</b>
      <p>The internal management network must be implemented as a single, dedicated, Layer 2
        broadcast domain for the exclusive use of each server cluster. Sharing of this network by
        more than one server cluster is not a supported configuration.</p><p>During the server
        software installation process, several network services such as DHCP, and PXE, are expected
        to run over the internal management network. These services are used to bring up the
        different hosts to an operational state. Therefore, it is mandatory that this network be
        operational and available in advance, to ensure a successful installation.</p><p>On each
        host, the internal management network can be implemented using a 10 Gb Ethernet port. In
        either case, requirements for this port are:</p><ul>
        <li>must be capable of PXE-booting</li>
        <li>can be used by the motherboard as a primary boot device</li>
      </ul></section>
    <section id="oam-network"><b>CAN/OAM Network</b>
      <p>You should ensure that the following services are available on the CAN/OAM Network:</p><ul>
        <li>
          <p>DNS Service - Needed to facilitate the name resolution of servers reachable on the
            CAN/OAM Network.</p>
          <p>The server can operate without a configured DNS service. However, a DNS service should
            be in place to ensure that links to external references in the current and future
            versions of the web administration interface work as expected.</p>
        </li>
        <li>
          <p>NTP Service - The Network Time Protocol (NTP) can be optionally used by the server
            controller nodes to synchronize their local clocks with a reliable external time
            reference. However, it is strongly suggested that this service be available, among other
            things, to ensure that system-wide log reports present a unified view of the day-to-day
            operations.</p>
        </li>
      </ul><p>The server compute nodes always use the controller nodes as the time server for the
        entire cluster.</p>
    </section>
    <section id="provider-network"><b>Provider Network</b>
      <p>There are no specific requirements for network services to be available on the provider
        network. However, you must ensure that all network services required by the guests running
        in the compute nodes are available. For configuration purposes, the compute nodes themselves
        are entirely served by the services provided by the controller nodes over the internal
        management network.</p></section>
    <section id="infrastructure-network"><b>Infrastructure Network</b>
      <p>This is an optional network.</p><p>As with the internal management network, the
        infrastructure network must be implemented as a single, dedicated, Layer 2 broadcast domain
        for the exclusive use of each server cluster.</p><p>Sharing of this network by more than one
        server cluster is not a supported configuration.</p><p>The infrastructure network can be
        implemented as a 10 Gb Ethernet network. In its absence, all infrastructure traffic is
        carried over the internal management network.</p></section>
  <section id="board-network"><b>Board Management Network</b>
      <p>Board Management CTL (IPMI Control) Network External access to the board management
      network, the board management modules are assigned IP addresses accessible from the OAM
      network, and the controller uses the OAM network to connect to them.</p></section>
    <section id="next">
      <title>Next step</title>
      <p><xref href="carrier-grade-install-pb-prereqs-GA.dita#topic7148">Installation
        Prerequisites</xref></p>
      <p>
        <xref type="section" href="#topic3485cgto"> Return to Top </xref>
      </p>
    </section>
    <!--
### Backup and Restore nodes {#backup-restore-nodes}

Backup and restore scripts and procedures are provided for the seed VM, undercloud, overcloud management controller (running singleton services like Sherpa), and the MySQL database deployed in the controller cluster. These scripts are to be used by administrators managing the OpenStack Cloud.

Backup and Restore of VM instances/snapshots and volumes/snapshots for workloads in the cloud is supported using the Object Storage service.

For more information see [HPE Helion OpenStack Back Up and Restore]

<a href="#top" style="padding:14px 0px 14px 0px; text-decoration: none;"> Return to Top </a>
-->
    <!-- ===================== horizontal rule ===================== -->
  </body>
</topic>
