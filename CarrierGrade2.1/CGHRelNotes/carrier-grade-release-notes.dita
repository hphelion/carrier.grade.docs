<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" >
<topic xml:lang="en-us" id="topic6108cgrn">
    <title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 2.1: Release Notes</title>
    <prolog>
        <metadata>
            <othermeta name="layout" content="default"/>
            <othermeta name="product-version" content="HP Helion Openstack Carreir Grade 1.1"/>
            <othermeta name="role" content="Storage Administrator"/>
            <othermeta name="role" content="Storage Architect"/>
            <othermeta name="role" content="Michael B"/>
            <othermeta name="product-version1" content="HP Helion Openstack Carreir Grade 1.1"/>
        </metadata>
    </prolog>
    <body>
        <p>Thank you for your interest in HPE Helion OpenStack This document provides an overview of
            the features contained within HPE Helion OpenStack version 2.0, including known issues
            and workarounds, and where to find further information on the product release.</p>
        <p>For more information on using HP Helion OpenStack Carrier Grade, see the <xref
                href="../Installation/carrier-grade-install-overview.dita#topic1925cgio">HP Helion
                OpenStack Carrier Grade Installation Guide</xref>, the <xref
                href="../carrier-grade-administration.dita#topic916cga">HP Helion OpenStack Carrier
                Grade Administrator Guide</xref> and the <xref
                href="../OperationsGuide/CGH-2-User-Overview.dita#jow1404333560080">HP Helion
                OpenStack Operations Guide</xref>. For information on using the HP Helion OpenStack
            Carrier Grade Developer API, including API definitions and usage descriptions, see the
                <xref href="../API/carrier-grade-api.dita#topic15959cga">HP Helion OpenStack Carrier
                Grade API and SDK Reference</xref>.</p>
        <section>See:<ul id="ul_z23_gdw_c5">
                <li><xref href="#topic6108cgrn/changes" format="dita"/></li>
                <li><xref href="#topic6108cgrn/usage" format="dita"/></li>
                <li><xref href="#topic6108cgrn/problems" format="dita"/></li>
                <li><xref href="carrier-grade-known-issues.dita#topic6108cgrn">Known Issues and Work
                        Arounds</xref></li>
            </ul></section>
        <section id="changes">
            <title>Changes in this release</title>
            <p><!--From WR jow1404333830815.xml and added info--></p>
            <p>The following enhancements were added for the HP Helion OpenStack Carrier Grade 2.0
                release:</p>
            <p>
                <ul id="ul_jqf_jgj_w5">
                    <li><b>Virtual control planes.</b> The HP Helion OpenStack controllers are
                        deployed onto virtual machines on a single host system. The controllers and
                        the lifecycle manager are deployed on the same host system. In HP Helion
                        OpenStack Carrier Grade, each of these components required a separate
                        server.</li>
                    <li><b>Installer and management interface.</b> The HP Helion OpenStack cloud can
                        be defined and deployed using a new web-based user interface, called the HCG
                        Dashboard. You can also use the dashboard to perform post-deployment
                        activities your cloud. </li>
                    <li><b>Support for restarting MySQL and RabbitMQ clusters</b>. In HP Helion
                        OpenStack Carrier Grade 2.1, the controllers are virtual machines on a
                        single server. In the event that server goes down, you will need to manually
                        restart the MySQL servers and RabbitMQ after the server is restarted. The
                        installation includes an Ansible playbook to manually restart these
                        services. See <xref
                            href="../OperationsGuide/Recover/CHG-2-recover.dita#topic5937recover"
                            >Restart MySQL and RabbitMQ</xref>.</li>
                    <!--<li><b>OpenSAF support.</b> The HP Helion OpenStack controller can optionally be deployed as KVM cluster (optional) using OpenSAF for Service Availability. OpenSAF is an open source middleware consistent with Service Availability Forum (SA Forum) specifications. SA goes beyond High Availability (HA) requirements. <b><i>From http://devel.opensaf.org/</i></b> OpenSAF must be installed prior to starting the HP Helion OpenStack Carrier Grade installation. Specific steps to integrate OpenSAF are provided in the installation sections.</li>-->
                </ul>
            </p>
        </section>
        <section id="usage"><title>Usage Caveats</title><b>Backup files in cloud directories can
                cause installation to fail</b>
            <p>During the HP Helion OpenStack Carrier Grade installation, you will need to create
                and edit a number of JSON configuration files. You should create backups of these
                files, in the event you need to reinstall. Create the backups in a directory on
                    <codeph>/root/</codeph> directory or on a remote system. Do not store backups of
                the JSON files inside your cloud directory or any where inside the
                    <codeph>/var/hlm/clouds</codeph> directory. </p><!--From WR jow1404333831397.xml--><p>
                <b>VMs reported as ACTIVE before compute nodes are recovered</b></p><p>During a
                system recovery (for example, after a site power outage), when the controller is
                available but before the compute nodes are available, the Nova service shows an
                    <b>Active</b> status for VMs . Until the compute nodes are available, this
                should be an <b>Error</b> status.</p><p>
                <b>Controller swact raises spurious ssh security warning</b></p><p>On ssh login to
                the active controller after a controller swact, a security warning appears, saying
                the host identification has changed. This occurs because the ssh keys are not
                currently synchronized across controllers. It can be disregarded. </p><p>
                <b>Mismatch of interface settings in LAG group</b></p><p>If the interfaces in a LAG
                group have mismatched speed or duplex settings, they are marked as incompatible by
                the system. To prevent this, ensure both interfaces in a LAG group use the same
                speed and duplex settings.</p><p>
                <b>Storage or compute node must be re-added after MAC address change on management
                    interface</b></p><p>For a compute or storage node, any change to the management
                interface configuration that results in a change of MAC address requires the node to
                be re-installed. The management interface MAC address can change if the physical
                Ethernet port is changed (for example, from eth1 to eth2), or if a LAG configuration
                is changed in a way that removes the Ethernet port associated with the LAG MAC
                address (for example, if the interface originally used for PXE boot is removed or
                replaced).</p><p>
                <b>Instance cannot be launched with a specified port ID</b></p><p>Use of the
                    <codeph>--port-id</codeph> parameter when launching an instance results in
                command failure.</p><p>
                <b>Live migration resets uptime</b></p><p>When a VM is live-migrated, the uptime
                reported for the VM is reset to 0.</p><p>
                <b>Interface network type cannot be changed directly from SRIOV to
                data</b></p><p>For an interface using network type "SRIOV," the network type must be
                changed to "none" before it can be changed to "data."</p><p>
                <b>Glance image deletion does not release storage space</b></p><p>The storage space
                used by a glance image is not released when the image is deleted. To free the space
                for other uses, a glance-api restart is required.</p></section>
        <section id="problems">
            <title>Known Problems and Limitations</title>
            <p><!--<b>VMware VMK No Memory Error    </b> --></p>
            <!--<p>When powering on the ESX Compute Proxy VM, you might receive a <systemoutput>VMK_NO_MEMORY</systemoutput> error. This is a known problem with HP server and ESXi 5.x.</p><p>To fix this issue, upgrade to HP AMS version 10.0.1 and above. See <xref href="../Installation/CGH-2-install-vmware-workaround.dita#topic10581c2ivw">Fixing the VMware VMK_NO_MEMORY Error</xref>.</p><p>Comment: From jow1404333831397.xml and added info </p> NOT IN DENVER-->
            <p><b>Booting a VM from Remote Storage</b></p>
            <p>Due to performance and reliability reasons, booting a VM instance off a remote
                storage is not supported in the current release. The only supported options
                are:<!--HCG-1520--></p>
            <p>
                <ul id="ul_xk5_r31_fv">
                    <li>Using local storage on the compute (which implies that there would be No
                        support for HA features like Live Migration). Refer to <xref
                            href="http://gaf2871b9d2d13cf45c1306b35bf01764.cdn.hpcloudsvc.com/CGH-2-KVM-Admin.pdf"
                            format="pdf" scope="external">KVM Region Administrator Guide</xref> on
                        how to configure compute node to use local storage. </li>
                    <li>Using Cinder-Volumes (with 3Par or StoreVirtual VSA as volume
                        backends).</li>
                </ul>
            </p>
            <p><b>Use the CLI with the KVM Region </b></p>
            <p>When working with the servers in the KVM Region, do not use the Horizon interface.
                Please use the <xref href="http://docs.openstack.org/cli-reference/content/"
                    format="html" scope="external">OpenStack command-line interface CLI
                    commands</xref>. </p>
            <p><b>Potential Vulnerability with Intel® LAN Products with SR-IOV</b></p>
            <p>In Intel® LAN products with SR-IOV capability, under specific conditions, Virtual
                Machines (VMs) can cause network congestion spreading, a well-known side-effect of
                Ethernet flow control, which could affect other VMs as well as the Hypervisor
                itself.</p>
            <p>For more information, see the <xref
                    href="https://security-center.intel.com/advisory.aspx?intelid=INTEL-SA-00046&amp;languageid=en-fr"
                    format="html" scope="external">bulletin in the Intel Security Center</xref>.</p>
            <p id="passwprds"><b>Do not change OpenStack Service default passwords</b></p>
            <p>Changing the default password for Swift, Glance, Cinder results in failing of their
                respective cloud admin operations. </p>
            <p><!--HCG-919--></p>
            <p><b>Cinder Volume Backup is not working upon cloud deployment</b></p>
            <!-- CG-410 -->
            <p>Cinder Volume Backup is not working upon installation of HP Helion OpenStack Carrier
                Grade 2.0 The <codeph>cinder.backup.driver</codeph> file is not present in
                /etc/cinder/cinder.conf.</p>
            <p><b>SR-IOV limitations</b></p>
            <ul id="ul_pzl_ccw_c5">
                <li>
                    <p>SR-IOV is supported only for Intel 82599.</p>
                </li>
                <li>
                    <p>The maximum number of VFs per NIC is 32.</p>
                </li>
                <li>
                    <p>SR-IOV and PCI passthrough cannot both be used on the same provider
                        network.</p>
                </li>
                <li>SR-IOV is not supported on Mellanox NICs.
                    <!--Per Vlad, Sanjib, Shantanu email--></li>
            </ul>
            <p><b>Interface or interface consolidation limitations</b></p>
            <ul id="ul_qzl_ccw_c5">
                <li>
                    <p>VLAN over bonded interface without an assigned network type is not
                        supported.</p>
                </li>
                <li>
                    <p>Addition of an infrastructure interface after installation is not
                        functional.</p>
                </li>
                <li>
                    <p>Consolidation of the infrastructure network over the OAM network is not
                        supported.</p>
                </li>
                <li>
                    <p>Stacked VLANs are not supported. On a consolidated management or
                        infrastructure interface, a VLAN provider network can be associated directly
                        with the untagged interface; however, flat or VXLAN provider networks must
                        be associated with a consolidated VLAN data interface.</p>
                </li>
                <li>
                    <p>Interface profiles cannot be created for <!--AE and -->VLAN interface types.
                    </p>
                </li>
                <li>
                    <p>The <cmdname>system host-if-modify-ports</cmdname> command is deprecated.
                    </p>
                </li>
            </ul>
            <p id="mellanox"><b>Mellanox CX-3 NICs limitations</b></p>
            <ul id="ul_rzl_ccw_c5">
                <li>
                    <p>Mellanox CX-3 NIC is supported for use in the AVS vSwitch
                        only.<!--Per Vlad and Shantanu email--></p>
                </li>
                <li>
                    <p>For a Mellanox CX3, all ports must be used ether for data interfaces, or for
                        non-data interfaces. It is not possible to use some ports for data
                        interfaces and others for non-data interfaces on the same Mellanox CX3
                        NIC.</p>
                </li>
                <li>
                    <p>Jumbo frames are not supported on Mellanox NICs.</p>
                </li>
                <li>SR-IOV, PCI-Passthrough are not supported on Mellanox NICs.
                    <!--Per Vlad, Sanjib, Shantanu email--></li>
            </ul>
            <p><b>Installation does not fully utilize disks greater than two terabytes</b></p>
            <p>HP Helion OpenStack Carrier Grade in the KVM Region can be installed on disks greater
                than 2 TB, but only 2 TB of the disk is useable.</p>
            <!-- Remove per Hrushi email 7-2
        
            <p><b>Cannot create Cinder LVM volumes using disks greater than two
                terabytes</b></p>
            <p>Using a disk greater than 2 TB for Cinder LVM results in a
                    <filepath>config_controller</filepath> failure.</p>
          -->
            <p><b>Guest heartbeat and notification features are not fully validated.</b></p>
            <p>Heartbeat and notification services for VMs are not fully validated. </p>
            <p><b>Cinder API version generates a log warning</b></p>
            <p>The V1 API for Cinder in use by this version of HP Helion OpenStack Carrier Grade is
                deprecated, resulting in log warnings.</p>
        </section>
    </body>
</topic>
