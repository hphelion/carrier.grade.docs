<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept-wr id="jow1454354939252" xml:lang="en-us"><title ixia_locid="1">NUMA considerations</title><shortdesc ixia_locid="2"/><prolog><author ixia_locid="3">Craig Griffin</author></prolog><conbody><p ixia_locid="4">AVS will minimize the impacts of NUMA locality of VMs and physical NICs by optimizing the memory allocation scheme to match the NUMA topology.  This optimization of memory locality does not need to be configured; however consideration should be made for VM placement relative to the AVS core allocations.  For high throughput applications, it is therefore recommended to use NUMA node pinning via flavor extra specs to match the AVS NUMA node core assignment to avoid crossing the CPU interconnect link (QPI) for all network traffic.  In other words, it is not recommended to configure AVS on NUMA node 0 and restrict networking VMs to NUMA node 1.</p><p ixia_locid="5">AVS can also be configured in a split configuration where AVS cores are assigned to multiple NUMA nodes.  AVS will automatically isolate traffic to a particular NUMA node if it detects that the physical NICs assigned as data interfaces are also split in the same NUMA topology.  This permits traffic from a guest VM to be localized to the current NUMA node, without the need to cross the interconnect link between the CPU.  However, care must be taken that the underlying physical NIC configuration also respects the same localization of traffic to avoid traffic destined to the localized VM from being received on a different NUMA node.</p></conbody></concept-wr>