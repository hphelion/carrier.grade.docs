<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/topic.dtd" ><topic xml:lang="en-us" id="topic5937">
<title>HP Helion <tm tmtype="reg">OpenStack</tm> Carrier Grade 2.1: Centralized Logging
    Overview</title>
<prolog>
<metadata>
<othermeta name="layout" content="default"/>
<othermeta name="product-version" content="HP Helion OpenStack"/>
<othermeta name="product-version" content="HP Helion OpenStack 1.1"/>
<othermeta name="role" content="Systems Administrator"/>
<othermeta name="role" content="Cloud Architect"/>
<othermeta name="role" content="Storage Administrator"/>
<othermeta name="role" content="Network Administrator"/>
<othermeta name="role" content="Service Developer"/>
<othermeta name="role" content="Cloud Administrator"/>
<othermeta name="role" content="Application Developer"/>
<othermeta name="role" content="Network Engineer"/>
<othermeta name="role" content="Paul F"/>
<othermeta name="product-version1" content="HP Helion OpenStack"/>
<othermeta name="product-version2" content="HP Helion OpenStack 1.1"/>
</metadata>
</prolog>
<body>
    <p><!--PUBLISHED--><!--./commercial/GA1/1.1commerical.services-logging-overview.md--><!--permalink: /helion/openstack/1.1/services/logging/overview/--></p>
    <p>Because a typical HP Helion OpenStack Carrier Grade cloud consists of multiple servers,
      locating a specific log from a specific server can be difficult.</p>
    <p>The HP Helion OpenStack Carrier Grade Centralized Logging feature collects logs from the
      Standard Region servers on a central system, rather than leaving the logs scattered across the
      network. The administrator can use a single Kibana interface to view log information in
      charts, graphs, tables, histograms, and other forms.</p>
    <p>Centralized logging helps the administrator triage and troubleshoot the distributed HP Helion
      OpenStack Carrier Grade cloud deployment from a single location. The admin is not required to
      access the several remote servers (SSH) to view the individual log files.</p>
    <p>Centralized logging logs the following <xref
        href="../../Overview/carrier-grade.services-overview.dita">HP Helion services</xref>: </p>
    <ul id="ul_bwl_2gc_d5">
      <li>Identity (Keystone)</li>
      <li>Image Operations (Glance)</li>
      <li>Block Storage (Cinder)</li>
      <li>Orchestration (Heat)</li>
      <li>Ceilometer</li>
      <li>Compute Operations (Nova)</li>
    </ul>
    <p>In addition Centralized Logging also processes logs for the following HP Helion OpenStack
      features:</p>
    <ul>
      <li>HAProxy</li>
      <li>syslog</li>
      <li>keepalived </li>
    </ul>
    <p>This document describes the Centralized Logging feature and contains the following
      sections:</p>
    <ul>
      <li>
        <xref type="section" href="#topic5937/install">Installation</xref>
      </li>
      <li>
        <xref type="section" href="#topic5937/components">Centralized Logging components</xref>
      </li>
      <li>
        <xref type="section" href="#topic5937/types">Centralized Logging log types</xref>
      </li>
      <li>
        <xref type="section" href="#topic5937/kibana">Kibana configuration</xref>
      </li>
      <li><xref type="section" href="#topic5937/password"/></li>
      <li>
        <xref type="section" href="#topic5937/interface">Logging into Kibana</xref>
      </li>
      <li>
        <xref type="section" href="#topic5937/logs" />
      </li>
    </ul>
    <section id="install">
      <title>Installation</title>
      <p>The Centralized Logging feature is automatically installed on all controllers as part of
        the HP Helion OpenStack Carrier Grade installation.</p>
      <p>No specific configuration is required to use Centralized Logging. However, you can tune or
        configure the individual components as needed for your environment. Tuning and configuring
        these components is outside the scope of this document.</p>
    </section>
    <section id="components">
      <title>Centralized Logging components</title>
      <p>Centralized logging consists of several components, including Logstash, Elasticsearch,
        RabbitMQ, and Kibana.</p>
      <ul>
        <li>
          <p>
            <b>Beaver</b> is a python daemon that takes information in log files and sends the
            content to RabbitMQ.</p>
        </li>
        <li>
          <p>
            <b>RabbitMQ</b> is a message broker for collection of logging data across nodes.</p>
        </li>
        <li>
          <p>
            <b>logstash</b> is a log processing system for receiving, processing and outputting
            logs. logstash retrieves logs from RabbitMQ, processes and enriches the data, then
            stores the data in Elasticsearch.</p>
        </li>
        <li>
          <p>
            <b>Elasticsearch</b> is data store offering fast indexing and querying.</p>
        </li>
        <li>
          <p>
            <b>Kibana</b> is a client-side JavaScript application to visualize the data in
            Elasticsearch through a web browser. Kibana enables you to create charts and graphs
            using the log data.</p>
        </li>
      </ul>
      <p>These components are configured to work out-of-the-box and the admin should be able to view
        log data using the default configurations.</p>
      <p>At a high level, the Helion services forward logs to Beaver. Then, Beaver forwards JSON
        messages to RabbitMQ on the controller0 node. Logstash connects to RabbitMQ to read queued
        messages and process the messages according to the Logstash configuration file. Logstash
        then forwards the processed log files in Elasticsearch. Users can use the Kibana interface
        to view and analyze the information, as shown in the following figure:</p>
      <p>
        <image href="../../../media/CGH-2-admin-central-logging.png" placement="break"/>
      </p>
      <note>Logging requires 4GB of disk space to make sure that all logging messages are
        retained.</note>
    </section>
    <section id="types">
      <title>Centralized Logging log types</title>
      <p>The following table lists the types of logs collected by Centralized Logging and provides
        information on how the logs are maintained.</p>
      <table>
        <tgroup cols="6">
          <colspec colname="col1"/>
          <colspec colname="col2"/>
          <colspec colname="col3"/>
          <colspec colname="col4"/>
          <colspec colname="col5"/>
          <colspec colname="col6"/>
          <thead>
            <row>
              <entry>Data name</entry>
              <entry>Confidentiality</entry>
              <entry>Integrity</entry>
              <entry> Availability</entry>
              <entry>Backup?</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Log records</entry>
              <entry>Restricted</entry>
              <entry>High</entry>
              <entry>Medium</entry>
              <entry>No</entry>
              <entry>Log records have a limited life, and are not archived. The log file on the
                local filesystem provides a fallback source of logging data (up to 20GB or 45 days)
                if the logging system fails.</entry>
            </row>
            <row>
              <entry>Log metadata</entry>
              <entry>Restricted</entry>
              <entry>High</entry>
              <entry>Medium</entry>
              <entry>No</entry>
              <entry>Elasticsearch indexes logged data to allow flexible searching.</entry>
            </row>
            <row>
              <entry>Credentials</entry>
              <entry>Confidential</entry>
              <entry>High</entry>
              <entry>Medium</entry>
              <entry>No</entry>
              <entry>Credentials for access to Elasticsearch and RabbitMQ are stored in
                configuration files owned by root with mode 0600.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>Log rotation will happen daily or when the current logfile reaches 2GB, whichever happens
        sooner. The number of rotations held will be balanced to attempt to cap logs from all
        services at 200GB.</p>
    </section>
    <section id="kibana">
      <title>Kibana configuration</title>
      <p>You can use the Kibana dashboards to view log data. Kibana is a tool developed to create
        charts, graphs, tables, and histograms based on logs send to Elasticsearch by logstash.</p>
      <p>While creating Kibana dashboards is beyond the scope of this document, it is important to
        know that you can use the default Kibana dashboards or create custom dashboards. The
        dashboards are JSON files that you can modify or create new dashboards based on existing
        dashboards.</p>
      <note>Kibana is client-side software. To operate properly, the browser must be able to access
        port 81 on the HLM host.</note>
    </section>
    <section id="password"><title>Changing the default Kibana password</title>Follow these steps to
      change the default password of the Kibana web interface. <p>
        <ol id="ol_jqr_4tk_f5">
          <li>Log into one of the controller nodes in the Standard Region.</li>
          <li>Delete the Kibana password
            file.<codeblock>rm /etc/logstash/kibana.htpasswd</codeblock></li>
          <li>Execute the followinf command:
              <codeblock>htpasswd -b -c /etc/logstash/kibana.htpasswd kibana &lt;new-password&gt;</codeblock><p>Where
              &lt;new-password> is the new Kibana password</p></li>
          <li>Execute the following command to restart the apache2
            service<codeblock>service apache2 restart</codeblock></li>
          <li>Repeat these steps on all controllers in the Standard Region.</li>
        </ol>
      </p></section>
    <section id="interface">
      <title>Logging into Kibana</title>
      <p>Launch a web browser on the seed cloud host to the following IP address, using the CLM
        virtual IP address for the controller you want to monitor:</p>
      <codeblock><codeph>http://&lt;CLM_IP&gt;:81</codeph></codeblock>
      <p>
        <b>Example:</b>
      </p>
      <codeblock><codeph>http://192.0.2.2:81</codeph></codeblock>
      <p>Log in with the user name/password. The user name is <codeph>kibana</codeph> and the
        password is the password you created in the previous section.</p>
      <!--<p>To retrieve the CLM IP:</p><ol><li>From the HLM host log in to a controller as super user: <codeblock><codeph>ssh heat-admin@&lt;undercloud IP&gt; 
sudo su - </codeph></codeblock></li><li>Enter the following command to display the password: <b>NEED COMMAND OR REMOVE</b><codeblock><codeph>cat </codeph></codeblock><p>Make note of the password.</p></li></ol>-->
    </section>
    <section id="logs">
      <title>Adjusting how long logs are retained</title>
      <p conref="../../Troubleshooting/CGH-2-troubleshooting.dita#topic10581c2t/logs1"/>
      <p conref="../../Troubleshooting/CGH-2-troubleshooting.dita#topic10581c2t/logs2"/>
    </section>
    <section id="info">
      <title>For more information</title>
      <p>For information the centralized logging components, use the following links:</p>
      <ul>
        <li>
          <xref href="http://logstash.net/" scope="external" format="html">Logstash</xref>
        </li>
        <li>
          <xref href="http://www.elasticsearch.org/" scope="external" format="html"
            >Elasticsearch</xref>
        </li>
        <li>
          <xref href="http://www.rabbitmq.com/" scope="external" format="html">RabbitMQ</xref>
        </li>
        <li><xref href="http://www.elasticsearch.org/guide/en/kibana/current/_dashboard_schema.html"
            scope="external" format="html">Kibana Dashboard</xref>
        </li>
      </ul>
    </section>
  </body>
</topic>
